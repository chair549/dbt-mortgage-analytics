# ğŸ¡ Mortgage Analytics Project (dbt + Databricks)

This project demonstrates a complete, production-style data transformation pipeline using **dbt Cloud** and **Databricks**, with a Power BI dashboard as the final business deliverable. The aim was to replicate a real-world analytics engineering workflow â€” from raw data ingestion, transformation, and testing, to dashboarding and insights delivery.
---

## ğŸš€ Tools Used

- **Databricks SQL Warehouse** â€“ Cloud-based compute and data storage
- **dbt Cloud** â€“ Transformation, testing, documentation, modular SQL
- **Power BI** â€“ Dashboard and business-facing analytics
- **GitHub** â€“ Version control and portfolio hosting

---

## ğŸ“Š Power BI Dashboard

The dashboard visualizes key mortgage KPIs sourced from the dbt-transformed tables in Databricks.

It includes:

- Total + average loan amounts
- Settlement vs withdrawal rates
- Loan distribution by size, region, and type
- Approval timelines
- Conditional approval risk bands

ğŸ“¸ Preview:

![Mortgage Dashboard](mortgage_dashboard.PNG)

---

## ğŸ§  What I Learned (and struggled through)

- ğŸ“¡ **Connecting dbt to Databricks**: Setting up tokens, profiles.yml, catalogs (`workspace` vs `main`), and schema access was non-trivial. I ran into multiple `NO_SUCH_CATALOG_EXCEPTION` and connection hangs â€” and learned how to debug them using Databricks SQL Explorer and proper config formatting.
- âš™ï¸ **Understanding dbtâ€™s flow**: Realized how `sources`, `staging`, and `marts` fit together conceptually and in code.
- ğŸ§ª **Writing modular, tested SQL**: dbt encouraged me to split raw data cleaning into clean staging models before aggregating for final reporting.
- ğŸ” **Iteration**: I rebuilt my project from scratch after hitting the dbt Cloud free project limit â€” this helped solidify my understanding of every part of the pipeline.

---
## ğŸ§± Project Setup & What I Built

This project was created entirely in **dbt Cloud**, connected to a **Databricks SQL Warehouse**, with the following key files and configurations:

### ğŸ”Œ dbt â†’ Databricks Connection

Connecting dbt to Databricks involved setting up:

- A **Databricks SQL Warehouse** using the Community Edition
- A **personal access token** from Databricks
- A `profiles.yml` file in dbt Cloud that contained:
  - `host` (your Databricks workspace URL)
  - `http_path` (from the SQL Warehouse settings)
  - `token` (for authentication)
  - `catalog` and `schema` (`workspace.mortgage_analytics`)
  
I initially encountered errors such as:

- `NO_SUCH_CATALOG_EXCEPTION`
- Hanging connections when running `dbt run`
- Confusion around `workspace` vs `main` vs `hive_metastore`

These were resolved by:
- Choosing the right **catalog**: `workspace` (since `main` didnâ€™t exist in my account)
- Creating a **schema** manually in Databricks (`mortgage_analytics`)
- Matching the `profiles.yml` to my SQL warehouse settings

---

### ğŸ“„ Key Files I Created

| File Name                      | Purpose                                                  |
|-------------------------------|----------------------------------------------------------|
| `src_mortgage_data.yml`       | Declares the raw Databricks table as a dbt **source** and applies **tests** (e.g. not_null, unique) on key fields like `application_submission_id` |
| `stg_mortgage_data.sql`       | Cleans the raw mortgage data: casting types, normalizing fields, formatting dates, removing inconsistencies â€” creates a staging layer for analysis |
| `mortgage_metrics.sql`        | Aggregates the staging data to generate KPIs like average loan amount, settlement rate, conditional approval rate, loan counts by type and state |
| `mortgage_metrics.yml` *(optional)* | Provides docs/tests for the final model (e.g. not null on numeric KPIs, column descriptions for Power BI users) |
| `dbt_project.yml`             | Core dbt config that defines model folders and build behavior |

Each file plays a role in building **modular, testable, and reusable** SQL models that layer from raw â†’ clean â†’ business metrics.


## ğŸ“¦ Project Structure

```text
dbt-mortgage-analytics/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ src_mortgage_data.yml       # Source config + field-level tests
â”‚   â”‚   â””â”€â”€ stg_mortgage_data.sql       # Casts, cleans, standardizes raw data
â”‚   â””â”€â”€ marts/
â”‚       â””â”€â”€ mortgage_metrics.sql        # Business-facing KPIs & aggregations
â”œâ”€â”€ dbt_project.yml                     # Core dbt config (name, paths, etc.)
â””â”€â”€ README.md                           # This file
